# -*- coding: utf-8 -*-
"""NER_Transformer.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1BsfupfIXkVZX-Wp_fz7NuEFVG0Bw_7mn

## Biblioteka i dane
"""

!wget http://mozart.ipipan.waw.pl/~grzewo/archive.zip
!unzip archive.zip
!head -20 train.txt

!pip install -q simpletransformers

"""## PrzyciÄ™cie daych"""

!wc -l train.txt

!head -50000 train.txt > small_train.txt

"""## Wandb"""

!pip install wandb -qqq
import wandb
wandb.login()

"""## Trening"""

from simpletransformers.ner.ner_model import NERModel

train_args = {
    'evaluate_during_training': True,
    'evaluate_during_training_steps': 100,
    'num_train_epochs': 3,
    'save_eval_checkpoints': False,
    'train_batch_size': 16,
    'eval_batch_size': 16,
    'overwrite_output_dir': True,
    'wandb_project': "ner_distilbert"
}

# Create a NERModel
model = NERModel('distilbert', 'distilbert-base-uncased', use_cuda=True, cuda_device=0, args=train_args)


# Train the model
model.train_model('small_train.txt', eval_data="valid.txt")

# Evaluate the model
result, model_outputs, predictions = model.eval_model('test.txt')

# Check predictions
print(predictions[:5])
wandb.finish()

print(result)

"""## Sprawdzenie modelu"""

predictions, raw_outputs = model.predict(["My name is Gregory and I am from Poland"])
print(predictions)

print(raw_outputs)