{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -q simpletransformers"
      ],
      "metadata": {
        "id": "WfXKx4rdVLAY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tXyfwQMLOXOL"
      },
      "outputs": [],
      "source": [
        "!wget https://nlp.stanford.edu/projects/snli/snli_1.0.zip\n",
        "!unzip snli_1.0.zip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "OPVEFSedOe3d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def read_snli(data_dir, is_train):\n",
        "    \"\"\"Read the SNLI dataset into premises, hypotheses, and labels.\"\"\"\n",
        "    def extract_text(s):\n",
        "        # Remove information that will not be used by us\n",
        "        s = re.sub('\\\\(', '', s)\n",
        "        s = re.sub('\\\\)', '', s)\n",
        "        # Substitute two or more consecutive whitespace with space\n",
        "        s = re.sub('\\\\s{2,}', ' ', s)\n",
        "        return s.strip()\n",
        "    label_set = {'entailment': 0, 'contradiction': 1, 'neutral': 2}\n",
        "    file_name = os.path.join(data_dir, 'snli_1.0_train.txt'\n",
        "                             if is_train else 'snli_1.0_test.txt')\n",
        "    with open(file_name, 'r') as f:\n",
        "        rows = [row.split('\\t') for row in f.readlines()[1:]]\n",
        "    premises = [extract_text(row[1]) for row in rows if row[0] in label_set]\n",
        "    hypotheses = [extract_text(row[2]) for row in rows if row[0] in label_set]\n",
        "    labels = [label_set[row[0]] for row in rows if row[0] in label_set]\n",
        "    df = pd.DataFrame(list(zip(premises, hypotheses, labels)),\n",
        "               columns =[\"text_a\", \"text_b\", \"labels\"])\n",
        "    return df"
      ],
      "metadata": {
        "id": "1WbYEM4aQkiI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = read_snli(\"snli_1.0\", is_train=True)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "nadvqsKyREvy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = df[:5000]\n",
        "eval_df = df[15000:15500]\n",
        "test_df = df[15500:16000]"
      ],
      "metadata": {
        "id": "K5eU0X_mTiuJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from simpletransformers.classification import ClassificationModel\n",
        "\n",
        "\n",
        "# Training arguments\n",
        "train_args = {\n",
        "    'evaluate_during_training': True,\n",
        "    'num_train_epochs': 4,\n",
        "    'save_eval_checkpoints': False,\n",
        "    'train_batch_size': 32,\n",
        "    'eval_batch_size': 32,\n",
        "    'overwrite_output_dir': True,\n",
        "    'wandb_project': \"snli_distilbert\"\n",
        "}\n",
        "\n",
        "model = ClassificationModel('albert', 'albert-base-v2', num_labels=3, use_cuda=True, cuda_device=0, args=train_args)\n",
        "\n",
        "# Train model\n",
        "model.train_model(train_df, eval_df=eval_df)\n",
        "result, model_outputs, wrong_predictions = model.eval_model(test_df)"
      ],
      "metadata": {
        "id": "6XofYMqESLzm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "69DsALfkENZh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}